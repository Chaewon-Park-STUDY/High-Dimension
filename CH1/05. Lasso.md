## üìå Lasso
: Least Absolute Shrinkage and Selection Operator

### ‚úÖ Definition
**1Ô∏è‚É£ Constraint Form**
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/7.png" width="500"/>


**2Ô∏è‚É£ Penalty Form**
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/8.png" width="400"/>
- Œª ‚â• 0 controls amount of shrinkage
- Lasso leads to **‚ú®sparsity‚ú®** in Œ≤(exact zeros)
* Sparsity
=> Among many Œ≤s, only a few components are 'non-zero'
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/9.jpeg" width="400"/>
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/11.png" width="300"/>
- small estimation error implies better estimator; meaning Œ≤ÃÇ  well estimate Œ≤
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/10.jpeg" width="450"/>






## Lasso
```python
from sklearn.linear_model import Lasso

model_name = "lasso"
alpha = 1
fig = plt.figure(figsize=(6, 3))
ax = fig.add_subplot(111)
lasso = Lasso(alpha=alpha)
lasso.fit(X_train, y_train)
y_pred = lasso.predict(X_test)
rmse = np.round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)
coef = pd.Series(data=lasso.coef_, index=X_train.columns).sort_values()
ax.bar(coef.index, coef.values)
ax.set_xticklabels(coef.index, rotation=90)
ax.set_title("{0}: alpha = {1}, rmse = {2}".format(model_name, alpha, rmse))
```

---


* Ï∞∏Í≥†ÏûêÎ£å:  
- https://www.youtube.com/watch?v=sGTWFCq5OKM
- https://www.youtube.com/watch?v=Zb-6ZhT2zBE
