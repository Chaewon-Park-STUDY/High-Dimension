
### ✅ Subgradient(KKT) for Lasso
<img width="509" height="341" alt="image" src="https://github.com/user-attachments/assets/1d1eff12-6c70-4d51-b3bb-b21980e25164" />
<br>
<hr>





- Lasso doesn't have a closed form solution, unless all the variables are orthogonal
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/8.png" width="400"/>
- Cannot take the derivative of this function but we can define the subgradient
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/23.png" width="400"/>
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/24.jpeg" width="400"/>

<br>


### ✅ Choosing λ for Lasso

- Choosing the appropriate λ is critical
- **Cross-Validation** : Most popular method to choose λ
- Randomly split the data into K subgroups with almost equal size
- We don't split the variables(p), but samples(n)

<br>
<img width="600" height="201" alt="image" src="https://github.com/user-attachments/assets/856589a8-59ad-421f-a842-16fb11cdf191" />
<br>
-For small  λ, estimator is almost same as the least squares estimator








<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/25.jpeg" width="600"/>
<br>
<img src="https://raw.githubusercontent.com/Chaewon-Park-STUDY/High-Dimension/main/images/26.jpeg" width="500"/>


- Out of the candidate λ, choose λ that provides the smallest CV-error
- Can also apply CV to Ridge
